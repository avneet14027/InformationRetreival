from __future__ import division
import string
import operator
import bm251
import scipy
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer



#file read, store docs in list

tokenize = lambda doc: doc.lower().split(" ")

doc_list=[]
doc_name=[]


def file_read(file_name,doc_list):
	document = []
	with open(file_name) as f:
    		document = f.read()
		document = unicode(document,errors='ignore')
	doc_list.append(document)


def read_documents(outer_index,in_index,file_name):
	for i in range(1,outer_index):
		for j in range(1,in_index):
			fileName=file_name+str(i) + "/a" + str(j) + ".txt.clean"
			doc_name.append(fileName)
			file_read(fileName,doc_list)
	

def get_documents():
	folder_list=["S08/data/set","S09/data/set","S10/data/set"]
	indiceList=[[5,11],[6,11],[7,11]]
	for i,name in enumerate(folder_list):
		read_documents(indiceList[i][0],indiceList[i][1],name)
		
		

#Main program execution begins here
if __name__ == "__main__":

	#Load the list of documents
	get_documents()
	#print(doc_list)
	
	#Count vectorizer
	sklearn_tf = CountVectorizer(tokenizer=tokenize)
	tf_representation=sklearn_tf.fit_transform(doc_list)
	#print(tf_representation)

	#print doc_list	
	sklearn_tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize)
	sklearn_representation = sklearn_tfidf.fit_transform(doc_list)

			
	raw_input("Press enter to continue!")

	#Execute Query and generate TFID_matrix
	query = ""give an example of the many sukarno era monuments in the city"
	query_tf = sklearn_tf.transform([query])

	cx = scipy.sparse.coo_matrix(query_tf)
	col_indices=[]

	for i,j,v in zip(cx.row, cx.col, cx.data):
		#print "(%d, %d), %s" % (i,j,v)
		col_indices.append(j)

	#print(query_tf)	
	result=bm251.apply(col_indices,sklearn_representation,tf_representation)
	result_sorted_indices=sorted(range(len(result)), key=lambda k: result[k])
	
	
	result_sorted_indices.reverse()

	#print(result_sorted)
	for index in (result_sorted_indices):
		print(doc_name[index],result[index],"Index:",index)
	
	
	
	
	
	
	

